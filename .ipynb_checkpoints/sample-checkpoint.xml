<!-- id's have to be unique across all files in all projects -->
<!-- (use these parameters to compute dependencies on task runs and create truly parallel execution using threading) -->
<!-- Mode can be table, view, temp, incremental, or None (if you do not want to save output as sql table) -->

<connection id="connection_1" host="127.0.0.1" port="5432" username="admin" password="pwd123"></connection>

<task id="task_1" schedule="CRON * * * * *" active="true" steps="t0,t1,t2,t3,t4" force_build="true"></task>

<python id="t0" table="PYTHON_API_USERS_LANDING" schema="DATA" database="RAW" handler="extract" connection="connection_1" materialization="temp" inputs="" schema_change="drop_and_recreate">
    import pandas as pd
    import requests
    
    def extract():
        r = requests.get("https://www.api.com/v1/endpoint/")
        r_json = r.json()
        df = pd.DataFrame(r_json)
        return df
</python>

<python id="t1" table="USERS_STAGE_1" schema="DATA" database="STAGE" handler="transform" connection="connection_1" materialization="temp" inputs="t0" schema_change="drop_and_recreate">

    import pandas as pd
    import requests
    
    def transform(t0):
        df['FULL_NAME'] = df['FRIST_NAME'] + " " + df['LAST_NAME']
        return df

</python>

<sql id="t2" table="USERS" schema="DATA" database="RAW" connection="connection_1" materialization="incremental" primary_key="ID" inputs="t1" schema_change="drop_and_recreate">

    SELECT 
    * 
    FROM t1

</sql>

<sql id="t3" table="USERS_CONF" schema="DATA" database="CONF" connection="connection_1" materialization="view" inputs="t2" schema_change="drop_and_recreate">

    SELECT
    ID::INT AS ID,
    FULL_NAME::STRING AS FULL_NAME
    FROM t2

</sql>

<sql id="t4" table="USERS" schema="DATA" database="CORE" connection="connection_1" materialization="incremental" primary_key="ID" inputs="t3" schema_change="recreate">

    SELECT 
    * 
    FROM t3

</sql>


